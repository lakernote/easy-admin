# 构建镜像 docker-compose build
# 启动容器命令 docker-compose up 在后台执行该服务可以加上 -d,docker-compose up -d
# 停止删除命令 docker-compose down 删除容器同时删除卷docker-compose down -v
version: "3.4"
# 项目名称
name: easy-admin

services:
  # 定义了mysql数据库
  mysql:
    # 容器名
    container_name: mysql8
    # 镜像
    image: mysql:8.3
    # 指定容器退出后的重启策略为始终重启，但是不考虑在Docker守护进程启动时就已经停止了的容器
    restart: unless-stopped
    command: [ "--max_connections=300","--default-authentication-plugin=mysql_native_password" ]
    networks:
      - app_net
    # 映射端口
    ports:
      - "3306:3306"
    # 设置环境变量,相当于docker run命令中的-e
    environment:
      TZ: Asia/Shanghai
      # 初始化的数据库名称
      MYSQL_DATABASE: easy-admin
      # 设置root用户密码
      MYSQL_ROOT_PASSWORD: 123456
    # 数据卷挂载路径设置,将本机目录映射到容器目录
    volumes:
      - mysqlData:/var/lib/mysql
      # 将宿主机的 /var/lib/mysql/ 目录挂载到容器内的 /var/lib/mysql/ 目录
      # 这样做的目的通常是为了将 MySQL 数据库的持久化存储在宿主机的数据卷中，以防止容器删除后数据丢失。
      #  - /var/lib/mysql/:/var/lib/mysql/
      #  表示将宿主机中的 ./sql目录中的文件挂载到容器内的 /docker-entrypoint-initdb.d/目录中，
      #  同时设置挂载为只读模式 (ro，即 read-only)。这个配置通常用于向 MySQL 数据库容器中初始化数据，比如在容器启动时执行 SQL 脚本以创建数据库表和插入初始数据。
      - ./sql:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost" ]
      interval: 10s
      timeout: 10s
      retries: 3

  # 定义了redis
  redis:
    container_name: redis6
    build: ./docker/redis
    restart: unless-stopped
    networks:
      - app_net
    ports:
      - "6379:6379"
    volumes:
      - redisData:/data
      - redisData:/usr/local

  # 定义kafka 从 3.3 版本后，Kafka 引入了 KRaft 来替代 ZooKeeper
  kafka:
    container_name: kafka37
    image: bitnami/kafka:3.7
    # 容器的重启策略 确保服务在意外停止后自动重启，减少手动干预的需求
    restart: unless-stopped
    # 控制容器使用宿主机的网络
    # host模式: 让容器直接使用宿主机的网络接口，容器和宿主机之间没有网络隔离
    # network_mode: host
    networks:
      - app_net
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      # Listeners
      # INTERNAL EXTERNAL自己定义的
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://0.0.0.0:9091,EXTERNAL://0.0.0.0:9092,CONTROLLER://:9093

      # 支持外部客户端访问，这里配置的是外部访问的地址 必须是对外的IP，客户端连接时必须是IP 10.140.201.179，不能是0.0.0.0
      # 有时候配置 localhost也行，但是有时候会报错，所以最好配置对外的IP
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9091,EXTERNAL://localhost:9092
      # Broker之间的连接用 INSIDE 监听器
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
    volumes:
      - kafkaData:/bitnami/kafka # 持久化数据存储路径
  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:7.8.0
    hostname: kafka-schema-registry
    ports:
      - "8082:8081"
    container_name: kafkaSchemaRegistry
    restart: always
    networks:
      - app_net
    environment:
      # 连接到 Kafka Broker，而不是 Zookeeper
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:9091'  # 连接到 Kafka Broker
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    depends_on:
      - kafka
volumes:
  # 自定义的卷名,存储的路径不好找
  redisData:
  mysqlData:
  kafkaData:

networks:
  # 配置docker network
  app_net:
    # 桥接模式是 Docker 默认的网络驱动程序，用于在容器间创建桥接网络，使它们能够相互通信
    driver: bridge
    ipam:
      driver: default
      config:
        # 子网络
        - subnet: 178.18.0.0/16